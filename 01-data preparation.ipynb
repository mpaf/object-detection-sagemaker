{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Object Detection\n",
    "\n",
    "Object detection is the process of identifying and localizing objects in an image. A typical object detection solution takes an image as input and provides a bounding box on the image where an object of interest is found. It also identifies what type of object the box encapsulates. To create such a solution, we need to acquire and process a traning dataset, create and setup a training job for the alorithm so that it can learn about the dataset. Finally, we can then host the trained model in an endpoint, to which we can supply images.\n",
    "\n",
    "This notebook is an end-to-end example showing how the Amazon SageMaker Object Detection algorithm can be used with a publicly available dataset of bird images. We demonstrate how to train and to host an object detection model based on the Caltech Birds (CUB 200 2011) dataset. Amazon SageMaker’s object detection algorithm uses the Single Shot multibox Detector (SSD) algorithm, and this notebook uses a ResNet base network with that algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before preparing the data, there are some initial steps required for setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial SageMaker Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# this will create a 'default' sagemaker bucket if it doesn't exist (sagemaker-region-accountid)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)\n",
    "prefix = \"DEMO-ObjectDetection-birds\"\n",
    "\n",
    "# Get the ARN of the IAM role used by this Studio instance to pass to training jobs and other Amazon SageMaker tasks.\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing additional packages\n",
    "\n",
    "This notebook requires two additional Python packages: * OpenCV is required for gathering image sizes and flipping of images horizontally. * The MXNet runtime is required for using the im2rec tool - you can also use the MXNet kernel provided by SageMaker Studio which includes these packages and libraries by default. If using another kernel you can try running:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install mxnet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the required packages are importable\n",
    "import cv2\n",
    "import mxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Unpacking the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)     \n",
    "# download('http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz')\n",
    "# CalTech's download is (at least temporarily) unavailable since August 2020.\n",
    "\n",
    "# Can now use one made available by fast.ai .\n",
    "download(\"https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Unpack and then remove the downloaded compressed tar file\n",
    "!gunzip -c ./CUB_200_2011.tgz | tar xopf -\n",
    "!rm CUB_200_2011.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file parameters define names and locations of metadata files for the dataset. A description of the different files can be found under\n",
    "\n",
    "./CUB_200_2011/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"CUB_200_2011/\"\n",
    "IMAGES_DIR = BASE_DIR + \"images/\"\n",
    "\n",
    "CLASSES_FILE = BASE_DIR + \"classes.txt\"\n",
    "BBOX_FILE = BASE_DIR + \"bounding_boxes.txt\"\n",
    "IMAGE_FILE = BASE_DIR + \"images.txt\"\n",
    "LABEL_FILE = BASE_DIR + \"image_class_labels.txt\"\n",
    "\n",
    "TRAIN_LST_FILE = \"birds_ssd_train.lst\"\n",
    "VAL_LST_FILE = \"birds_ssd_val.lst\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "utils.show_species(IMAGES_DIR, \"010.Red_winged_Blackbird\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the RecordIO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import utils\n",
    "\n",
    "SIZE_COLS = [\"idx\", \"width\", \"height\"]\n",
    "SIZE_FILE = BASE_DIR + \"sizes.txt\"\n",
    "\n",
    "utils.gen_image_size_file(IMAGES_DIR, IMAGE_FILE, SIZE_COLS, SIZE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RecordIO files can be created using the im2rec tool (images to RecordIO), which takes as input a pair of list files, one for training images and the other for validation images. Each list file has one row for each image. For object detection, each row must contain bounding box data and a class label.\n",
    "\n",
    "For the CalTech birds dataset, we need to convert absolute bounding box dimensions to relative dimensions based on image size. We also need to adjust class id’s to be zero-based (instead of 1 to 200, they need to be 0 to 199). This dataset comes with recommended train/test split information (“is_training_image” flag) but in this notebook we will create a random train/test split with a specific train/test ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating LST files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import utils\n",
    "\n",
    "# To speed up training and experimenting, you can use a small handful of species.\n",
    "# To see the full list of the classes available, look at the content of CLASSES_FILE.\n",
    "CLASSES = [17, 36, 47, 68, 73]\n",
    "\n",
    "TRAIN_LST_FILE = \"birds_ssd_sample_train.lst\"\n",
    "VAL_LST_FILE = \"birds_ssd_sample_val.lst\"\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "IM2REC_SSD_COLS = [\n",
    "    \"header_cols\",\n",
    "    \"label_width\",\n",
    "    \"zero_based_id\",\n",
    "    \"xmin\",\n",
    "    \"ymin\",\n",
    "    \"xmax\",\n",
    "    \"ymax\",\n",
    "    \"image_file_name\",\n",
    "]\n",
    "\n",
    "train_df, val_df = \\\n",
    "    utils.gen_list_files(SIZE_FILE, BBOX_FILE, IMAGE_FILE, LABEL_FILE,\n",
    "                   CLASSES,\n",
    "                   IM2REC_SSD_COLS,\n",
    "                   TRAIN_RATIO,\n",
    "                   TRAIN_LST_FILE, VAL_LST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few records from the training list file to understand better what is being fed to the RecordIO files.\n",
    "\n",
    "The first column is the image number or index. The second column indicates that the label is made up of 2 columns (column 2 and column 3). The third column specifies the label width of a single object. In our case, the value 5 indicates each image has 5 numbers to describe its label information: the class index, and the 4 bounding box coordinates. If there are multiple objects within one image, all the label information should be listed in one line. Our dataset contains only one bounding box per image.\n",
    "\n",
    "The fourth column is the class label. This identifies the bird species using a zero-based class id. Columns 4 through 7 represent the bounding box for where the bird is found in this image.\n",
    "\n",
    "The classes should be labeled with successive numbers and start with 0. The bounding box coordinates are ratios of its top-left (xmin, ymin) and bottom-right (xmax, ymax) corner indices to the overall image size. Note that the top-left corner of the entire image is the origin (0, 0). The last column specifies the relative path of the image file within the images directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -3 $TRAIN_LST_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating RecordIO .rec files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, you will download the im2rec.py tool for pre-processing and packing images together in a RecordIO records file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py\",\n",
    "    \"im2rec.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the records file while resizing the shorter edge of image to 256 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "RESIZE_SIZE = 256\n",
    "\n",
    "!python im2rec.py --resize $RESIZE_SIZE --pack-label birds_ssd_sample $IMAGES_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our packed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_iter = mx.io.ImageRecordIter(\n",
    "    path_imgrec='./birds_ssd_sample_val.rec',\n",
    "    data_shape=(3, 500, 500), # output data shape. An RESIZE_SIZE X RESIZE_SIZE region will be cropped from the original image.\n",
    "    batch_size=4, # number of samples per batch\n",
    "    label_width=7\n",
    "    #resize=256 # resize the shorter edge to 256 before cropping\n",
    "    # ... you can add more augmentation options as defined in ImageRecordIter.\n",
    "    )\n",
    "data_iter.reset()\n",
    "batch = data_iter.next()\n",
    "data = batch.data[0]\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(data[i].asnumpy().astype(np.uint8).transpose((1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/mxnet-1.8-cpu-py37-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
